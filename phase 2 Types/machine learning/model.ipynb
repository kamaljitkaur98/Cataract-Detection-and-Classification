{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.feature import  greycomatrix, greycoprops\n",
    "import re\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "rf_class = RandomForestClassifier(n_estimators=100)\n",
    "svm_rbf=svm.SVC(kernel='rbf',gamma=0.001,C=10)\n",
    "svm_linear=svm.SVC(kernel='linear',gamma=0.001,C=10)\n",
    "#knn= KNeighborsClassifier(n_neighbors=2, metric='minkowski', p=2) \n",
    "#log = LogisticRegression(solver='liblinear')\n",
    "abc = AdaBoostClassifier(n_estimators=100,learning_rate=1)\n",
    "#xgb = XGBClassifier(n_estimators=100)\n",
    "xgb = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=500,\n",
    " max_depth=10,\n",
    " min_child_weight=1,\n",
    " gamma=0.1,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " nthread=4,\n",
    " seed=27)\n",
    "\n",
    "model_names={\"Random Forest\":rf_class,\"AdaBoostClassifier\":abc,\"XGBClassifier\":xgb}\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model:\n",
    "    rf_class = RandomForestClassifier(n_estimators=100)\n",
    "    abc = AdaBoostClassifier(n_estimators=100,learning_rate=1)\n",
    "    xgb = XGBClassifier(learning_rate =0.1,\n",
    "     n_estimators=500,\n",
    "     max_depth=10,\n",
    "     min_child_weight=1,\n",
    "     gamma=0.1,\n",
    "     subsample=0.8,\n",
    "     colsample_bytree=0.8,\n",
    "     nthread=4,\n",
    "     seed=27)\n",
    "\n",
    "    model_names={\"Random Forest\":rf_class,\"AdaBoostClassifier\":abc,\"XGBClassifier\":xgb}\n",
    "    def __init__(self,dataset,**kwargs):\n",
    "        size = None\n",
    "        if len(kwargs.items())!=0:\n",
    "           size = kwargs['size']\n",
    "        self.dataset = dataset\n",
    "        self.images_sift, self.glcm, self.images_sift_glcm,self.labels = self.generateFeatureDataset(self.dataset,size)\n",
    "    \n",
    "    def generateFeatureDataset(self,dataset,size):\n",
    "        subdirs = [x[0] for x in os.walk(dataset)]\n",
    "        file_names=[]\n",
    "        for sub_dir in subdirs[1:4]:\n",
    "            mypath = sub_dir\n",
    "            sub_folder_file_names = [mypath+\"/\"+f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "            file_names += sub_folder_file_names\n",
    "        min_dim = []\n",
    "        images_sift = []\n",
    "        glcm=[]\n",
    "        labels = []\n",
    "        size = size\n",
    "        sift = cv2.xfeatures2d.SIFT_create()\n",
    "        for i, file in enumerate(file_names):\n",
    "            image = cv2.imread(file,0)\n",
    "            if size is not None:\n",
    "                image = cv2.resize(image, (size, size), interpolation = cv2.INTER_AREA)\n",
    "            img_arr = np.array(image)\n",
    "            gCoMat = greycomatrix(img_arr, [1], [0],256,symmetric=True, normed=True) # Co-occurance matrix\n",
    "            contrast = greycoprops(gCoMat, prop='contrast')[0][0]\n",
    "            dissimilarity = greycoprops(gCoMat, prop='dissimilarity')[0][0]\n",
    "            homogeneity = greycoprops(gCoMat, prop='homogeneity')[0][0]\n",
    "            energy = greycoprops(gCoMat, prop='energy')[0][0]\n",
    "            correlation = greycoprops(gCoMat, prop='correlation')[0][0]\n",
    "            #entropy = greycoprops(gCoMat, prop='entropy')[0][0]\n",
    "            variance = greycoprops(gCoMat, prop='variance')[0][0]\n",
    "            keypoints, descriptors = sift.detectAndCompute(image,None)\n",
    "            descriptors=np.array(descriptors)      \n",
    "            descriptors=descriptors.reshape(-1)\n",
    "            min_dim.append(len(descriptors))\n",
    "            glcm.append([contrast,dissimilarity,homogeneity,energy,correlation])\n",
    "            images_sift.append(descriptors)\n",
    "            if re.split(r'[`[\\]\\'\\\\/]', file_names[i])[-2]=='mild':\n",
    "                labels.append(0)\n",
    "            elif re.split(r'[`[\\]\\'\\\\/]', file_names[i])[-2] == 'normal':\n",
    "                labels.append(1)\n",
    "            else :\n",
    "                labels.append(2)\n",
    "\n",
    "        images_sift_final = [features[:min(min_dim)] for features in images_sift]\n",
    "        images_sift_final =np.array(images_sift_final)\n",
    "        glcm=np.array(glcm)\n",
    "        images_sift_glcm=np.concatenate((images_sift_final,glcm),axis=1)\n",
    "        return images_sift_final,glcm,images_sift_glcm,labels\n",
    "    \n",
    "    def testing(self,model_name,X_train, X_test, y_train, y_test):\n",
    "        model=model_names[model_name]\n",
    "        model.fit(X_train,y_train)\n",
    "        yhat = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, yhat)\n",
    "        acc = str(round(acc, 2)*100) + '%'\n",
    "        return [model_name,acc]\n",
    "    \n",
    "    \n",
    "    def result(self,dataset):\n",
    "        min_max_scaler = preprocessing.StandardScaler()\n",
    "        x_scaled = min_max_scaler.fit_transform(dataset)\n",
    "        df=pd.DataFrame(data=x_scaled)\n",
    "        #df = pd.concat([df,target_df],axis=1)\n",
    "        df['label']=self.labels\n",
    "        df=df.sample(frac=1)\n",
    "        X=df.drop(['label'], axis = 1)\n",
    "        y=df['label']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "        model_result = []\n",
    "        for model in [\"Random Forest\",\"AdaBoostClassifier\",\"XGBClassifier\"]:\n",
    "            model_result.append(self.testing(model,X_train, X_test, y_train, y_test))\n",
    "        print(tabulate(model_result, headers=['Model', 'Result'], tablefmt='orgtbl'))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def run(self):\n",
    "        print(\"\\n\")\n",
    "        print(\"\\t---SIFT---\")\n",
    "        self.result(self.images_sift)\n",
    "        print(\"\\n\")\n",
    "        print(\"\\t---Glcm---\")\n",
    "        self.result(self.glcm)\n",
    "        print(\"\\n\")\n",
    "        print(\"\\t---SIFT + GLCM---\")\n",
    "        self.result(self.images_sift_glcm)\n",
    "              \n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Running 224 preprocessed images******************\n",
      "\n",
      "\n",
      "\t---SIFT---\n",
      "| Model              | Result             |\n",
      "|--------------------+--------------------|\n",
      "| Random Forest      | 53.0%              |\n",
      "| AdaBoostClassifier | 40.0%              |\n",
      "| XGBClassifier      | 55.00000000000001% |\n",
      "\n",
      "\n",
      "\t---Glcm---\n",
      "| Model              | Result   |\n",
      "|--------------------+----------|\n",
      "| Random Forest      | 94.0%    |\n",
      "| AdaBoostClassifier | 94.0%    |\n",
      "| XGBClassifier      | 95.0%    |\n",
      "\n",
      "\n",
      "\t---SIFT + GLCM---\n",
      "| Model              | Result   |\n",
      "|--------------------+----------|\n",
      "| Random Forest      | 81.0%    |\n",
      "| AdaBoostClassifier | 85.0%    |\n",
      "| XGBClassifier      | 95.0%    |\n"
     ]
    }
   ],
   "source": [
    "print(\"***************Running 224 preprocessed images******************\")\n",
    "\n",
    "model_224=model('../Deep learning/preprocessed images_224')\n",
    "model_224.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Running 40 preprocessed images******************\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "variance is an invalid property",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-9d8fe525b9af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"***************Running 40 preprocessed images******************\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel_40\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../Deep learning/preprocessed_images_40'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel_40\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-a71e8a982809>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m            \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages_sift\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglcm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages_sift_glcm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerateFeatureDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgenerateFeatureDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-a71e8a982809>\u001b[0m in \u001b[0;36mgenerateFeatureDataset\u001b[1;34m(self, dataset, size)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mcorrelation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgreycoprops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgCoMat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'correlation'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;31m#entropy = greycoprops(gCoMat, prop='entropy')[0][0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[0mvariance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgreycoprops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgCoMat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'variance'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m             \u001b[0mkeypoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescriptors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msift\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mdescriptors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdescriptors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skimage\\feature\\texture.py\u001b[0m in \u001b[0;36mgreycoprops\u001b[1;34m(P, prop)\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%s is an invalid property'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;31m# compute property for each GLCM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: variance is an invalid property"
     ]
    }
   ],
   "source": [
    "print(\"***************Running 40 preprocessed images******************\")\n",
    "\n",
    "model_40=model('../Deep learning/preprocessed_images_40',size=128)\n",
    "model_40.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Running original preprocessed images******************\n",
      "\n",
      "\n",
      "\t---SIFT---\n",
      "| Model              | Result   |\n",
      "|--------------------+----------|\n",
      "| Random Forest      | 45.0%    |\n",
      "| AdaBoostClassifier | 47.0%    |\n",
      "| XGBClassifier      | 51.0%    |\n",
      "\n",
      "\n",
      "\t---Glcm---\n",
      "| Model              | Result   |\n",
      "|--------------------+----------|\n",
      "| Random Forest      | 83.0%    |\n",
      "| AdaBoostClassifier | 66.0%    |\n",
      "| XGBClassifier      | 82.0%    |\n",
      "\n",
      "\n",
      "\t---SIFT + GLCM---\n",
      "| Model              | Result             |\n",
      "|--------------------+--------------------|\n",
      "| Random Forest      | 66.0%              |\n",
      "| AdaBoostClassifier | 56.99999999999999% |\n",
      "| XGBClassifier      | 84.0%              |\n"
     ]
    }
   ],
   "source": [
    "print(\"***************Running original preprocessed images******************\")\n",
    "\n",
    "model_1000=model('../Deep learning/preprocessed images')\n",
    "model_1000.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Running original Dataset images******************\n",
      "\n",
      "\n",
      "\t---SIFT---\n",
      "| Model              | Result   |\n",
      "|--------------------+----------|\n",
      "| Random Forest      | 39.0%    |\n",
      "| AdaBoostClassifier | 43.0%    |\n",
      "| XGBClassifier      | 45.0%    |\n",
      "\n",
      "\n",
      "\t---Glcm---\n",
      "| Model              | Result   |\n",
      "|--------------------+----------|\n",
      "| Random Forest      | 95.0%    |\n",
      "| AdaBoostClassifier | 63.0%    |\n",
      "| XGBClassifier      | 93.0%    |\n",
      "\n",
      "\n",
      "\t---SIFT + GLCM---\n",
      "| Model              | Result   |\n",
      "|--------------------+----------|\n",
      "| Random Forest      | 52.0%    |\n",
      "| AdaBoostClassifier | 76.0%    |\n",
      "| XGBClassifier      | 95.0%    |\n"
     ]
    }
   ],
   "source": [
    "print(\"***************Running original Dataset images******************\")\n",
    "\n",
    "model_org=model('../Deep learning/Dataset')\n",
    "model_org.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import pandas as pd\n",
    "# target_df = pd.get_dummies(labels,prefix=\"label\")\n",
    "# target_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
